<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="https://hlgr360.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hlgr360.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-05-03T13:36:49+00:00</updated><id>https://hlgr360.github.io/blog/feed.xml</id><title type="html">Holger Reinhardt</title><subtitle>I love building products.</subtitle><entry><title type="html">Accessing AWS RDS from local shell</title><link href="https://hlgr360.github.io/blog/blog/accessing-rds-from-cmdln/" rel="alternate" type="text/html" title="Accessing AWS RDS from local shell" /><published>2020-05-03T00:00:00+00:00</published><updated>2020-05-03T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/accessing-rds-from-cmdln</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/accessing-rds-from-cmdln/">&lt;p&gt;Another weekend, another gotcha. The task for today was to enable my son to connect his upcoming Firefox Theme manager to a MySQL database. After some frustrating attempts to install MySQL bloatware locally, I suggested he quickly spins up a RDS instance in our AWS account to test it.&lt;/p&gt;

&lt;p&gt;Well, if life would be just that easy. Getting the instance up and running was easy enough, but then we hit a wall by trying to connect to it locally. See, the default setting of AWS RDS is to create the DB instance in a lockdown state - without public internet access, sending an unsuspecting developer on a goose chase around the documentation trying to figure out how to reconfigure it. And yes, I know its a good practice to create the database instance in lock-down state, but not everyone likes to chase down the config settings to be able to run a quick experiment.&lt;/p&gt;

&lt;p&gt;As it turns out there are two settings, you need to change to be able to connect to your RDS instance from your local system:&lt;/p&gt;

&lt;p&gt;(1) When you create the RDS instance do not use the &lt;code class=&quot;highlighter-rouge&quot;&gt;Easy Create&lt;/code&gt; option but stick to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Standard Create&lt;/code&gt;. Fill in the configuration parameters as you see fit but pay attention when you come to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Connectivity&lt;/code&gt; Settings panel. Unfold the &lt;code class=&quot;highlighter-rouge&quot;&gt;Additional Connectivity Settings&lt;/code&gt; and set the &lt;code class=&quot;highlighter-rouge&quot;&gt;Public Accessible&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;Yes&lt;/code&gt;. Then continue to create your database instance.&lt;/p&gt;

&lt;p&gt;(2) After the database has been created, select the database instance in the AWS RDS Management console. Under &lt;code class=&quot;highlighter-rouge&quot;&gt;Connectivity &amp;amp; Security&lt;/code&gt; select the &lt;code class=&quot;highlighter-rouge&quot;&gt;VPC Security Group&lt;/code&gt; under the &lt;code class=&quot;highlighter-rouge&quot;&gt;Security&lt;/code&gt; column. The &lt;code class=&quot;highlighter-rouge&quot;&gt;EC2 Management&lt;/code&gt; page opens with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Security Group&lt;/code&gt; pre-selected. Select &lt;code class=&quot;highlighter-rouge&quot;&gt;Action / Edit Inbound Roules&lt;/code&gt;. Add a new rule for your database (i.e. custom-tcp and port or MYSQL/Aurora in our case for MySQL). For &lt;code class=&quot;highlighter-rouge&quot;&gt;Source&lt;/code&gt; use &lt;code class=&quot;highlighter-rouge&quot;&gt;My IP&lt;/code&gt; to allow AWS to determine your local IP. Add the rule and you should be able to connect from your local CLI to the RDS instance.&lt;/p&gt;

&lt;p&gt;Thats it - may the code be with you.&lt;/p&gt;

&lt;h4 id=&quot;further-reading&quot;&gt;Further reading&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Troubleshooting.html#CHAP_Troubleshooting.Connecting&quot;&gt;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Troubleshooting.html#CHAP_Troubleshooting.Connecting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_SettingUp.html#CHAP_SettingUp.SecurityGroup&quot;&gt;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_SettingUp.html#CHAP_SettingUp.SecurityGroup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="aws" /><summary type="html">How to access a AWS RDS instance from your local command line</summary></entry><entry><title type="html">Installing brew and lazydocker on RPi</title><link href="https://hlgr360.github.io/blog/blog/installing-brew-on-rpi/" rel="alternate" type="text/html" title="Installing brew and lazydocker on RPi" /><published>2020-03-30T00:00:00+00:00</published><updated>2020-03-30T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/installing-brew-on-rpi</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/installing-brew-on-rpi/">&lt;p&gt;This one is a quick one. I came across a very cool project called &lt;a href=&quot;https://github.com/jesseduffield/lazydocker&quot;&gt;lazydocker&lt;/a&gt; which provides a simple terminal UI for both docker and docker-compose. If you remember &lt;a href=&quot;https://en.wikipedia.org/wiki/Norton_Commander&quot;&gt;Norton Commander&lt;/a&gt;, well then you know what I am talking about ;).&lt;/p&gt;

&lt;p&gt;Turns out, something in me does not like the idea of using a dockerized tool to manage …. docker. Always on the lookout for a quick fix I saw that I could install &lt;code class=&quot;highlighter-rouge&quot;&gt;lazydocker&lt;/code&gt; using &lt;a href=&quot;https://brew.sh&quot;&gt;brew&lt;/a&gt; (which I know well enough from MacOS).&lt;/p&gt;

&lt;p&gt;So how about installing &lt;code class=&quot;highlighter-rouge&quot;&gt;brew&lt;/code&gt; and then install &lt;code class=&quot;highlighter-rouge&quot;&gt;lazydocker&lt;/code&gt; using brew - should be easy enough, or? And guess what - it was.&lt;/p&gt;

&lt;p&gt;Installing &lt;code class=&quot;highlighter-rouge&quot;&gt;brew&lt;/code&gt; on RPi was as easy as following &lt;a href=&quot;https://docs.brew.sh/Homebrew-on-Linux&quot;&gt;the instructions&lt;/a&gt;. And then simply follow the instructions on &lt;a href=&quot;https://github.com/jesseduffield/lazydocker&quot;&gt;lazydocker&lt;/a&gt; - and it all worked within 5 min.&lt;/p&gt;

&lt;p&gt;Wow ..&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="rpi" /><category term="docker" /><summary type="html">Installing a simple terminal UI for both docker and docker-compose on RPi</summary></entry><entry><title type="html">Running pihole on RPi at startup</title><link href="https://hlgr360.github.io/blog/blog/start-pihole-on-rpi-at-start/" rel="alternate" type="text/html" title="Running pihole on RPi at startup" /><published>2020-03-29T00:00:00+00:00</published><updated>2020-03-29T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/start-pihole-on-rpi-at-start</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/start-pihole-on-rpi-at-start/">&lt;p&gt;Another weekend, and this time we will take a crack at running services like the &lt;a href=&quot;https://pi-hole.net&quot;&gt;pihole&lt;/a&gt; not from the command line, but at startup.&lt;/p&gt;

&lt;p&gt;This is kind of a hygiene task from our last project of running &lt;a href=&quot;https://pi-hole.net&quot;&gt;pihole&lt;/a&gt; using &lt;a href=&quot;https://hlgr360.github.io/blog/blog/installing-docker-and-compose-on-rpi/&quot;&gt;docker and docker-compose on RPi&lt;/a&gt;. Back then I gave him a link to &lt;a href=&quot;https://www.dexterindustries.com/howto/run-a-program-on-your-raspberry-pi-at-startup/&quot;&gt;Five Ways To Run a Program On Your Raspberry Pi At Startup&lt;/a&gt; and asked him to implement the &lt;a href=&quot;https://www.dexterindustries.com/howto/run-a-program-on-your-raspberry-pi-at-startup/#systemd&quot;&gt;systemd&lt;/a&gt; approach. And while it took him a few tries he was able to get a first version to work. With that in place I was willing to reconfigure our Wifi router to use the ‘pihole’ as primary DNS server.&lt;/p&gt;

&lt;p&gt;Fast forward a couple of days and I noticed a lack of network activity on the pi - and after some more digging it turned out that the ‘pihole’ service was not longer running. But only this time the response of my son to my request of him debugging his solution was - how can I say - less than enthusiastic. He had already moved on and much rather annoyed his mother to install a 3D scanning app on her iPhone for him to be able to generate 3D models in &lt;a href=&quot;https://www.blender.org&quot;&gt;blender&lt;/a&gt; for his next ‘Unity’ project.&lt;/p&gt;

&lt;p&gt;Oh well, so much for trying to teach him persistence and pride in ‘a job well done’. But I was also curious myself why it stopped working. So the old man got to work.&lt;/p&gt;

&lt;p&gt;If you need a refresher on how to use ‘systemctl’ command I can highly recommend &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units&quot;&gt;How to use systemctl&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo systemctl status pihole.service&lt;/code&gt; to the rescue. A noticed quickly that he had simply copied the &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt; CLI command to into the service definition and called it day. Well, there are a few things wrong with that - systemd is running as root at startup and therefor does not need &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt;, plus not using absolute file paths pretty much invites problems since startup services like &lt;code class=&quot;highlighter-rouge&quot;&gt;systemd&lt;/code&gt; has no home directory and path settings like the &lt;code class=&quot;highlighter-rouge&quot;&gt;pi&lt;/code&gt; user. Also he did not set the proper dependencies to run the &lt;code class=&quot;highlighter-rouge&quot;&gt;pihole&lt;/code&gt; after the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.service&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;But I would lie to say that I am all up on the latest on how to run docker as part of a &lt;code class=&quot;highlighter-rouge&quot;&gt;systemd&lt;/code&gt; service. But this query on &lt;a href=&quot;https://github.com/docker/compose/issues/4266&quot;&gt;How to make a Systemd Unit for docker-compose&lt;/a&gt; gave me most of what I needed, in particular &lt;a href=&quot;https://github.com/docker/compose/issues/4266#issuecomment-302813256&quot;&gt;this response&lt;/a&gt;. While playing around I did run into the problem of &lt;a href=&quot;https://stackoverflow.com/questions/31697828/docker-run-name-is-already-in-use-by-container&quot;&gt;docker run –&amp;gt; ‘name is already in use by container’&lt;/a&gt; which did explain to me the cleanup commands prior to executing the service start.&lt;/p&gt;

&lt;p&gt;Without much ado, here is my &lt;code class=&quot;highlighter-rouge&quot;&gt;pihole&lt;/code&gt; service definition.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# See https://github.com/docker/compose/issues/4266#issuecomment-302813256
[Unit]
Description=Starts pihole (an network wide ad blocker)
Requires=docker.service
After=docker.service

[Service]
Restart=always
WorkingDirectory=/lib/systemd/system/pihole.service.d

# Remove old containers, images and volumes
ExecStartPre=/usr/local/bin/docker-compose down -v
ExecStartPre=/usr/local/bin/docker-compose rm -fv
#ExecStartPre=-/bin/bash -c '/usr/bin/docker volume ls -qf &quot;name=pihole*&quot; | xargs docker volume rm'
ExecStartPre=-/bin/bash -c '/usr/bin/docker network ls -qf &quot;name=piholeserviced_default&quot; | xargs docker network rm'
ExecStartPre=-/bin/bash -c '/usr/bin/docker ps -aqf &quot;name=pihole&quot; | xargs docker rm'

# Compose up
ExecStart=/usr/local/bin/docker-compose up

# Compose down, remove containers and volumes
ExecStop=/usr/local/bin/docker-compose down -v

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I placed the above file &lt;code class=&quot;highlighter-rouge&quot;&gt;pihole.service&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;/lib/systemd/system&lt;/code&gt; and created a directory &lt;code class=&quot;highlighter-rouge&quot;&gt;/lib/systemd/system/pihole.-service.d&lt;/code&gt; (set as &lt;code class=&quot;highlighter-rouge&quot;&gt;WorkingDirectory&lt;/code&gt; above). I placed the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file of the ‘pihole’ into that directory - which saved me from having to specify the compose file via the &lt;code class=&quot;highlighter-rouge&quot;&gt;-f&lt;/code&gt; command line parameter (remember that you can not assume to know from where the &lt;code class=&quot;highlighter-rouge&quot;&gt;systemd&lt;/code&gt; process is running - so using absolute paths is a must).&lt;/p&gt;

&lt;p&gt;All what was then left to do was the following commands:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo sudo systemctl daemon-reload&lt;/code&gt; # to reload the changed definition&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo systemctl start pihole.service&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo systemctl status pihole.service&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On that note - I guess what I still need to teach my son that a job is only done when its done.&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="rpi" /><category term="docker" /><summary type="html">How to run services on Raspberry Pi at startup</summary></entry><entry><title type="html">Install docker and docker-compose on RPi</title><link href="https://hlgr360.github.io/blog/blog/installing-docker-and-compose-on-rpi/" rel="alternate" type="text/html" title="Install docker and docker-compose on RPi" /><published>2020-03-08T00:00:00+00:00</published><updated>2020-03-08T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/installing-docker-and-compose-on-rpi</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/installing-docker-and-compose-on-rpi/">&lt;p&gt;Another weekend, another project of my son. For whatever reason he has suddenly become very privacy focused and asked me to sell his Alexa and run a &lt;a href=&quot;https://pi-hole.net&quot;&gt;pihole&lt;/a&gt; on one of our Raspberry Pi’s. Now - given that I had to reinstall the RPi multiple times after some of his other crafty experiments - this felt like a good time to use his enthusiasm and have him learn docker.&lt;/p&gt;

&lt;p&gt;But as usual (sadly I must admit), trying to find a simple step-by-step tutorial turned into a chase of breadcrumbs across the web. So for your and my benefit, here is a summary of my steps to get &lt;code class=&quot;highlighter-rouge&quot;&gt;docker&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; up and running on a RPi. After I had finished my setup I stumbled across &lt;a href=&quot;https://dev.to/rohansawant/installing-docker-and-docker-compose-on-the-raspberry-pi-in-5-simple-steps-3mgl&quot;&gt;Installing Docker and Docker Compose on the Raspberry Pi in 5 Simple Steps&lt;/a&gt; which further reduces the steps needed. Your leverage might vary, but from briefly reviewing it, it might do the trick as well.&lt;/p&gt;

&lt;p&gt;The following steps are based on &lt;a href=&quot;https://www.docker.com/blog/happy-pi-day-docker-raspberry-pi/&quot;&gt;Happy Pi Day with Docker and Raspberry Pi&lt;/a&gt; with the missing command for apt-key taken from &lt;a href=&quot;https://medium.com/@sh.tsang/installation-of-docker-3b18d9e70bea&quot;&gt;Docker Tutorial 1: Docker Installation in Ubuntu 18.04&lt;/a&gt; and &lt;a href=&quot;https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket&quot;&gt;How to fix docker: Got permission denied while trying to connect to the Docker daemon socket&lt;/a&gt; to allow the &lt;code class=&quot;highlighter-rouge&quot;&gt;pi&lt;/code&gt; user to run docker.&lt;/p&gt;

&lt;p&gt;Execute the following steps to install docker (details for each step see &lt;a href=&quot;https://www.docker.com/blog/happy-pi-day-docker-raspberry-pi/&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install apt-transport-https ca-certificates software-properties-common -y&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;curl -fsSL get.docker.com -o get-docker.sh &amp;amp;&amp;amp; sh get-docker.sh&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo usermod -aG docker pi&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo curl https://download.docker.com/linux/raspbian/gpg | sudo apt-key add -&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo add-apt-repository &quot;deb https://download.docker.com/linux/raspbian/ stretch stable&quot;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get update&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get upgrade&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl start docker.service&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker info&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If after the last step you get the following permission problem&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt; Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/json: dial unix /var/run/docker.sock: connect: permission denied&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Apply the following fix (from &lt;a href=&quot;https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo chmod 666 /var/run/docker.sock&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But installing &lt;code class=&quot;highlighter-rouge&quot;&gt;docker&lt;/code&gt; is only half the fun without &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; (taken from &lt;a href=&quot;https://dev.to/rohansawant/installing-docker-and-docker-compose-on-the-raspberry-pi-in-5-simple-steps-3mgl&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install libffi-dev libssl-dev&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install -y python python-pip&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get remove python-configparser&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo pip install docker-compose&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To see if it all works, run yourself a &lt;a href=&quot;https://www.portainer.io&quot;&gt;portainer&lt;/a&gt; instance on your RPi (inspired by &lt;a href=&quot;https://blog.hypriot.com/post/new-docker-ui-portainer/&quot;&gt;this&lt;/a&gt;). Create a &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file with the following content&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dockerui:
  image: portainer/portainer:arm
  restart: always
  volumes:
    - '/var/run/docker.sock:/var/run/docker.sock'
  expose:
    - 9000
  ports:
    - 8080:9000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;and run it in the same directory with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose up&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To find the corresponding &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; definition for &lt;code class=&quot;highlighter-rouge&quot;&gt;pihole&lt;/code&gt;, visit their github repo at &lt;a href=&quot;https://github.com/pi-hole/docker-pi-hole/&quot;&gt;https://github.com/pi-hole/docker-pi-hole/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Docker you should, if not want in installation hell you live.&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="rpi" /><category term="docker" /><summary type="html">Simple step-by-step recipe to install docker and docker-compose on Raspberry Pi</summary></entry><entry><title type="html">Install Kali Linux on USB with MacOS</title><link href="https://hlgr360.github.io/blog/blog/installing-kali-macos/" rel="alternate" type="text/html" title="Install Kali Linux on USB with MacOS" /><published>2020-02-25T00:00:00+00:00</published><updated>2020-02-25T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/installing-kali-macos</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/installing-kali-macos/">&lt;p&gt;I spend a couple of hours with my oldest son to setup Kali Linux with persistence on an USB stick using MacOS. For those of you who don’t know &lt;a href=&quot;https://www.kali.org&quot;&gt;Kali Linux&lt;/a&gt;, it is a special linux distro for penetration testing and network security. Well, my son claims he needs it because he is on the hook for a graded presentation in his school about ethical hacking. But I have my doubts if this is his sole motivation - I feel an equal part in this is his desire to (a) hack my laptop and (b) to circumvent the time limits I put on his MacBook. But do I prefer him playing his brains out in ‘Borderlands’ or use the opportunity for him to learn a thing or two.&lt;/p&gt;

&lt;p&gt;I still remember - back in the 80’s - the thrill of calling up an unlisted data phone line with my first modem. Back in the day my home was still called East Germany and owning a private data modem (courtesy of my father working in IT research) was somewhat unusual. I guess it was fun (and did not work) except 15 min someone called back but hang up without saying a word. Well, that certainly gave me the creeps. But nothing else happened and in the following years I graduated from a bootlegged and modded version of &lt;a href=&quot;https://en.wikipedia.org/wiki/CP/M&quot;&gt;CP/M&lt;/a&gt; to a East-German version of the &lt;a href=&quot;https://de.wikipedia.org/wiki/Spectral_(Heimcomputer)&quot;&gt;ZX Spectrum&lt;/a&gt;. Oh well, down memory lane ..&lt;/p&gt;

&lt;p&gt;Back to Kali Linux. While there are plenty of tutorials how to install a straight Kali Linux on an USB stick, there are none showing how to install Kali Linux on an USB stick with the ability to persist changes. Running Kali Linux in any meaningful way on a bootable USB stick on a MacBook requires the installation of the Broadcom network drivers to be able to connect to the network. Without &lt;a href=&quot;https://www.kali.org/docs/usb/kali-linux-live-usb-persistence/&quot;&gt;Persistence&lt;/a&gt; the Linux distro is pretty limited.&lt;/p&gt;

&lt;p&gt;The biggest problems we were facing were to format a limited partition on the USB stick in FAT32. Most tutorials assume that one wants to use the entire space for a single partition - which would not allow space for a secondary partition for persistence. And my trusted friend &lt;a href=&quot;https://gparted.org&quot;&gt;gparted&lt;/a&gt; can not resize the active partition which leaves us between &lt;a href=&quot;https://en.wikipedia.org/wiki/Between_a_Rock_and_a_Hard_Place&quot;&gt;a rock and a hard place&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So here are the steps on MacOS to get you setup (assumption is that you have access to ‘sudo’ from the command line):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Download the latest ‘kali-linux-2020.1-live-amd64.iso’ from &lt;a href=&quot;https://www.kali.org/downloads/&quot;&gt;https://www.kali.org/downloads/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Insert your USB stick and open a terminal:
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;diskutil list&lt;/code&gt; - find the disk id of your USB stick (in the following we assume &lt;code class=&quot;highlighter-rouge&quot;&gt;disk2&lt;/code&gt; for my 64 GB USB stick)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;diskutil eraseDisk FAT32 KALI MBRFormat disk2&lt;/code&gt; - creates a bootable FAT32 partition across the entire USB stick&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;diskutil list&lt;/code&gt; - validate the created partition on the USB stick (for me it would be &lt;code class=&quot;highlighter-rouge&quot;&gt;disk2s1&lt;/code&gt;)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;diskutil splitPartition disk2s1 FAT32 KALI 10%&lt;/code&gt; - resizes the partition &lt;code class=&quot;highlighter-rouge&quot;&gt;disk2s1&lt;/code&gt; to 10% of its original size (here = 6.3 GB)&lt;/li&gt;
      &lt;li&gt;Remove your USB stick&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Download and install &lt;a href=&quot;https://unetbootin.github.io&quot;&gt;unetbootin&lt;/a&gt; to be able to burn the iso to a single partition
    &lt;ul&gt;
      &lt;li&gt;(You will need ‘sudo’ rights for this tool to work)&lt;/li&gt;
      &lt;li&gt;Re-insert your USB stick&lt;/li&gt;
      &lt;li&gt;Select the downloaded iso image (or pick one of the pre-selected images for a different Linux flavor)&lt;/li&gt;
      &lt;li&gt;Select the above created partition on the USB stick&lt;/li&gt;
      &lt;li&gt;Burn away&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This creates a bootable USB stick with free space for creating a new partition under Kali Linux. Reboot your MacBook with the Option key pressed to enter the boot menu (see &lt;a href=&quot;https://support.apple.com/en-us/HT201255&quot;&gt;https://support.apple.com/en-us/HT201255&lt;/a&gt;). You should now be able to boot into Kali Linux.&lt;/p&gt;

&lt;p&gt;To add persistence open the &lt;code class=&quot;highlighter-rouge&quot;&gt;gparted&lt;/code&gt; under Linux and add a new ‘primary, ext3’ partition on your USB stick. Label it as ‘persistence’. After creating the new partition the only remaining task is the step 4 in &lt;a href=&quot;https://www.kali.org/docs/usb/kali-linux-live-usb-persistence/&quot;&gt;https://www.kali.org/docs/usb/kali-linux-live-usb-persistence/&lt;/a&gt; and you are done (after a reboot). (Note: I had to use vi to create the file as sudo).&lt;/p&gt;

&lt;p&gt;Enjoy .. but now I better watch out for my son’s diabolical laugh when he tries to DoS me .. but guess what, it is a challenge I gladly accept.&lt;/p&gt;

&lt;p&gt;Hacking you must, but with great power great responsibility comes.&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="security" /><summary type="html">Simple step-by-step recipe to install Kali Linux with Persistence using MacOS</summary></entry><entry><title type="html">Summary of ‘Digitale Leute’ 2019 in Cologne</title><link href="https://hlgr360.github.io/blog/blog/digital-leute-2019/" rel="alternate" type="text/html" title="Summary of 'Digitale Leute' 2019 in Cologne" /><published>2019-12-06T00:00:00+00:00</published><updated>2019-12-06T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/digital-leute-2019</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/digital-leute-2019/">&lt;p&gt;(this post was originally published on the &lt;a href=&quot;http://work.haufegroup.io&quot;&gt;Haufe Development Blog&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;On the 28th of November I attended the ‘Digitale Leute’ conference in Cologne for the very first time. The conference bills itself as a gathering of folks involved in creating and shaping digital products. So it wasn’t a pure tech conference (tech definitely took a back seat) nor about formal processes beloved by Agilistas and project managers but a conference for Product Owners (PO) and everyone with a responsibility or interest in shaping (digital) product creation and management. Being able to attend a day-long conference focussing on this inherent cross-functional topic was what drove my interest.&lt;/p&gt;

&lt;p&gt;Most big tech conferences just have a track for talks about managing digital products, but it is not what they are focussing on. Which is kind of odd if you think about the importance a PO has in the shaping of digital products. The most useful knowledge on everything around product management I had gotten so far was from conferences focussing on startups and a few blogs like &lt;a href=&quot;https://www.intercom.com/blog/product-and-design/&quot;&gt;Intercom&lt;/a&gt; and &lt;a href=&quot;https://foldingburritos.com/resources/&quot;&gt;Folding Burritos&lt;/a&gt; (this is the only one I found to take a deep dive on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kano_model&quot;&gt;Kano Model&lt;/a&gt; for product feature prioritization). Despite of countless attempts of established companies to copy startup practices and culture (and claiming success just one too many times), the inconvenient fact remains that managing a digital product within a more established company is very different than managing the product of a startup. Where as startups tend to thrive (or simply die) within a scarcity of resources and few or any process, digital products from big companies tend to stagnate and/or wither within a relative abundance of resources and lots of process. It does sometimes make you wonder if there is something similar to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Resource_curse&quot;&gt;Resource Curse&lt;/a&gt; in Economics in respect to new (digital) product development in mature companies. In fact I believe there is but lets keep that topic for another blog and stop here with &lt;a href=&quot;https://hlgr360.github.io/blog/blog/lean-entrepreneur-books/&quot;&gt;a link to an much earlier blog entry of mine&lt;/a&gt; with some literature and research about this topic.&lt;/p&gt;

&lt;p&gt;All I know is that a good PO is worth his or her weight in gold and then some. And I have had the privilege to meet quite a few of very good PO’s in more than one company. What struck me most is the diversity of their  backgrounds: from the more obvious project manager to the more surprising lawyer to the past entrepreneur - compared to the more predictable background of developers, POs hail from a wide variety of professions and backgrounds. Intrigued I was hoping to discover a conference with a a similar wide range of cross-functional topics.&lt;/p&gt;

&lt;p&gt;So lets get it out of the way: The conference did not quite live up to my expectation nor was I able to pick up any of the best practices and learnings from how other companies dealt with the challenge of managing digital products.&lt;/p&gt;

&lt;p&gt;It was really the format of the talks which worked against me learning anything. The vast majority of talks were structured as fireside chats, with a moderator and the presenter going through a mock-up conversation with a set of prepared questions. The absence of any summary on slides prevented any kind of condensed truths or lessons to be taken from the conversation. Now don’t get me wrong, I have had my fair share of complaining about the obsession with slides in the corporate world as well, but there are some situations (i.e. like conferences) where slides are very helpful in allowing condensed knowledge to be disseminated. Some of the best presenters I know will use slides that way (and no, I do not mean cat pictures). I often take pictures of slides during talks and review them later to write summaries for my team. A Fireside Chat is just a conversation jumping from one topic to the next and focusses more on the individual rather than the abstract. Unless you are able to transcribe the talk in near real-time, writing down one thing means missing the next two or three, with no chance of ever catching up. (Which does remind me of my early years as student when transcripts were not yet available). If I just want to be entertained, the fireside chat format is ok - but if I want to learn, it works against it.&lt;/p&gt;

&lt;p&gt;But not all hope is lost. I did attended two talks I found very interesting and - as a bonus - picked up a book &lt;a href=&quot;https://www.sipgate.de/18-work-hacks-buch-personalarbeit-hr&quot;&gt;‘18 Work Hacks from a company called ‘Sipgate’&lt;/a&gt; which was surprisingly interesting and relevant.&lt;/p&gt;

&lt;h3 id=&quot;do-things-which-do-not-scale-airbnb&quot;&gt;Do things which do not scale (AirBnB)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.digitale-leute.de/timeslot19/the-airbnb-formula/&quot;&gt;description&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Fun fact: the motto originates from the Y Combinator&lt;/li&gt;
  &lt;li&gt;Example taking pictures of an apartment to increase conversion&lt;/li&gt;
  &lt;li&gt;Imagining the ideal outcome and walk backwards (similar to AMZN start with the press release)&lt;/li&gt;
  &lt;li&gt;It won’t scale but it allows you go below the surface and really learn what matters&lt;/li&gt;
  &lt;li&gt;Once you know what matters, go back and think about how to scale it&lt;/li&gt;
  &lt;li&gt;Interesting twist to increase viral factor:
    &lt;ul&gt;
      &lt;li&gt;going onto an AirBnB experience should be so inspiring to go back and host one yourself on AirBnB&lt;/li&gt;
      &lt;li&gt;applicable to two-sided markets where the buyer can also become a seller&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;remote-teams&quot;&gt;Remote Teams&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.digitale-leute.de/timeslot19/go-home-to-go-big-why-distributed-teams-are-the-future-and-how-yours-can-become-one-too/&quot;&gt;description&lt;/a&gt; and &lt;a href=&quot;https://herbig.co/DL19&quot;&gt;slides&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Principle 1: If one person is remote, everyone is remote&lt;/li&gt;
  &lt;li&gt;Principle 2: The more emotional a topic is, the more synchronous you need to communicate
    &lt;ul&gt;
      &lt;li&gt;Communication tools are ranging from synchronous (talking) to asynchronous (email)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Every time ego or emotions are involved, go synchronous&lt;/strong&gt; (i.e. talk directly)&lt;/li&gt;
      &lt;li&gt;There is no wrong communication tool, there is only a wrong tool for a particular job&lt;/li&gt;
      &lt;li&gt;Rethink the daily
        &lt;ul&gt;
          &lt;li&gt;Rethink it as async (its not a forum for discussion anyhow) (Ugh, Agilistas will hate that, but it makes so much sense)&lt;/li&gt;
          &lt;li&gt;Rethink workshop
            &lt;ul&gt;
              &lt;li&gt;No holding of sticky notes into webcams&lt;/li&gt;
              &lt;li&gt;Use &lt;a href=&quot;https://en.wikipedia.org/wiki/Double_Diamond_(design_process_model)&quot;&gt;Double Diamond&lt;/a&gt; strategy&lt;/li&gt;
              &lt;li&gt;Probably not more than 4h, split into reasonable chunks&lt;/li&gt;
              &lt;li&gt;Scribble and scan, Use shared whiteboard&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Be explicit about downsides of remote teams&lt;/li&gt;
  &lt;li&gt;ire for soft skills like communication, empathy&lt;/li&gt;
  &lt;li&gt;Ask remote members to write a ‘remote’ manual for on-boarding of new team members&lt;/li&gt;
  &lt;li&gt;Enable people to connect:
    &lt;ul&gt;
      &lt;li&gt;Off-site for co-located teams is about work,&lt;/li&gt;
      &lt;li&gt;Off-site for remote team is about connecting&lt;/li&gt;
      &lt;li&gt;Idea: have permanent hangout session at the coffee machine&lt;/li&gt;
      &lt;li&gt;Evaluate tools like https://standups.io&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;workhacks-sipgate&quot;&gt;Workhacks (SIPGate)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;first &lt;a href=&quot;https://www.sipgate.de/blog/24-work-hacks&quot;&gt;25 Workhacks&lt;/a&gt; and the second &lt;a href=&quot;https://www.sipgate.de/18-work-hacks-buch-personalarbeit-hr&quot;&gt;18 workhacks&lt;/a&gt; book&lt;/li&gt;
  &lt;li&gt;18 Workshacks
    &lt;ul&gt;
      &lt;li&gt;Peer Recruiting
        &lt;ul&gt;
          &lt;li&gt;Can it be one more: How teams determine if they need to grow&lt;/li&gt;
          &lt;li&gt;How to write the profile: How teams write the job profile&lt;/li&gt;
          &lt;li&gt;How saying no can be a source of learning: The team recruiting process&lt;/li&gt;
          &lt;li&gt;Meet the team: The team interview process&lt;/li&gt;
          &lt;li&gt;Trialing a workday: Team co-working with applicants&lt;/li&gt;
          &lt;li&gt;Money, money, money: The pesky salary question&lt;/li&gt;
          &lt;li&gt;Welcome: On-boarding process&lt;/li&gt;
          &lt;li&gt;The buddy: Mentoring new employees&lt;/li&gt;
          &lt;li&gt;Peer feedback: How to give feedback during the trial period&lt;/li&gt;
          &lt;li&gt;Letting go: When things do not work out&lt;/li&gt;
          &lt;li&gt;Getting better: Learning on the job&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Respect and trust
        &lt;ul&gt;
          &lt;li&gt;Motivation: Intrinsic vs extrinsic motivation&lt;/li&gt;
          &lt;li&gt;Bridging: Cross-functional career paths&lt;/li&gt;
          &lt;li&gt;Leadership: Ad-hoc vs appointed&lt;/li&gt;
          &lt;li&gt;Feel good: Community building&lt;/li&gt;
          &lt;li&gt;Overtime: Quo vadis?&lt;/li&gt;
          &lt;li&gt;Time out: Work-live balance&lt;/li&gt;
          &lt;li&gt;Authenticity: Talk the talk, walk the walk.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Plus a very good section on books and links&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you made it this far, you might wonder about the half talk I mentioned above. I had some more notes on a few more talks but in the end they where just some disconnected snippets I managed to write down before loosing the thread. Since they are not telling a story, I decided to skip it and end it here.&lt;/p&gt;

&lt;p&gt;Attend conferences, you must. Yessss.&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="conferences" /><category term="culture" /><summary type="html">Two and a half talks and a book.</summary></entry><entry><title type="html">Designing Systems - Efficiency vs Flexibility</title><link href="https://hlgr360.github.io/blog/blog/efficiency-flexibility/" rel="alternate" type="text/html" title="Designing Systems - Efficiency vs Flexibility" /><published>2019-11-22T00:00:00+00:00</published><updated>2019-11-22T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/efficiency-flexibility</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/efficiency-flexibility/">&lt;p&gt;(this post was originally published on the &lt;a href=&quot;http://work.haufegroup.io&quot;&gt;Haufe Development Blog&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;This blog post was inspired by a deployment tool discussion while drafting engineering blueprints to converge the organization on common application patterns. Since I have been in this kind of discussions repeatedly, I wanted to take the time to write down some thoughts about tradeoffs in system design. While the example at hand is about deployment tooling, it applies equally for instance to system integration and system architecture.&lt;/p&gt;

&lt;p&gt;On a side note, I think that software engineering as a profession can learn a lot by studying &lt;a href=&quot;https://en.wikipedia.org/wiki/Systems_theory&quot;&gt;System Theory&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Control_theory&quot;&gt;Control Theory&lt;/a&gt; - I wish those two subjects would be taught as the foundational subjects in software engineering at school. If feels we are wasting a lot of time in software engineering rediscovering fundamental truths about complex systems which every social science and physics major learns in his or her first couple of years.&lt;/p&gt;

&lt;p&gt;But coming back to the discussion at hand. We discussed the pros and cons of encouraging the use of the native tooling of cloud providers like &lt;a href=&quot;https://aws.amazon.com/codestar/&quot;&gt;AWS Codestar&lt;/a&gt; and &lt;a href=&quot;https://azure.microsoft.com/en-us/services/devops/&quot;&gt;Azure DevOps&lt;/a&gt; vs standalone tooling like &lt;a href=&quot;https://jenkins.io&quot;&gt;Jenkins&lt;/a&gt; and &lt;a href=&quot;https://www.terraform.io&quot;&gt;Terraform&lt;/a&gt; and &lt;a href=&quot;https://serverless.com&quot;&gt;Serverless&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The main argument for the latter is flexibility. In my experience it is not the code which creates a lock-in to a particular vendor, but the tooling we use to deploy the code. Think about this for a second - while the code representing the actual business value is mostly benign to the place where we run it, it is the hidden investment in tooling and associated process which can and in most cases does create a vendor lock-in. And the reason is quite trivial - it is much easier to argue for an investment in changing code to create business value for customers. It is much harder to argue for investing into changing tools to end up in the exact same place from a business and customer perspective. Tooling is a hidden enabler, whereas code represents real value to the customer in form of features. Yet it is the hidden enable which creates the lock-in, not the code itself. If you picked the Cloud-vendor native tooling, do you really think you are ever going to change vendors again? Even when at some point your and your vendors interest start to diverge? Or if the vendor decides to moneytize a previously free service or becomes a reputational risk which is detrimental to your business?&lt;/p&gt;

&lt;p&gt;On the other hand maybe you are trying to optimize for the short to medium term and that risk is acceptable for you. Because if you spend too much time designing for hidden flexibility and correspondingly too little into visible customer value, you might be too late to capture the market opportunity. &lt;strong&gt;Dying in beauty is still dead.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;On the other side the argument is efficiency. Stuff just works, frictionless and convenient. Fast time to value, as most vendors would claim. And they are not wrong. Developer tooling from Microsoft and AWS simply works with their respective services.&lt;/p&gt;

&lt;p&gt;And you won’t encounter issues like the breaking changes to your terraform configuration when upgrading from terraform 0.11 to 0.12. This is a perfect example of the costs hidden in flexibility. The trigger for the upgrade is actually quite trivial: AWS has given notice that the node8 serverless runtime will be EOL at the end of the year. If you have deployed your serverless functions with terraform 0.11 you might be surprised to learn that in order to deploy node10 you need to upgrade to terraform 0.12. All is good until the first local run of the newly updated terraform: you learn you that you need to change your terraform files to match the new syntax. And conveniently it supplies a script for that too. All good so far. Since you might use Jenkins you will need to upgrade the terraform version there too. But latest at that point some yellow flags start to go up - you are now no longer changing single service deployment of your distributed application, but the global deployment tooling for all services of your application. And you start to wonder what will happen to all those non-Javascript services you have been deploying with terraform 0.11. Now you are in a tough place - will you upgrade the terraform files for all those none-affected services too? Who will spend the time to test all this functionality, when really you should be busy building the features customers are paying you for? You realize with a sinking heart that the only way out is for you to switch to &lt;a href=&quot;https://jenkins.io/doc/book/pipeline/docker/&quot;&gt;containerized builds in your Jenkins&lt;/a&gt; unless you are willing to do a forklift upgrade of your entire application.&lt;/p&gt;

&lt;p&gt;But here is the catch - once you create such a containerized deployment pipeline, you are playing - from a systems perspective - at a different league. You are now being able to deploy each service in true isolation to any provider and system of your choosing. Any subsequent update will not longer have any knock-on effect on other services.&lt;/p&gt;

&lt;p&gt;So while you incurred short term additional costs for simple system hygiene, the end result is actually a much better system for the mid to long-term. This is actually not a random outcome, but a systemic effect in open systems and is described as ‘anti-fragile’ by Nassim Taleb in his manifesto &lt;a href=&quot;https://www.amazon.com/gp/product/B009K6DKTS/&quot;&gt;Antifragile: Things that Gain from Disorder&lt;/a&gt;. Closed systems decay over time, whereas open systems can be reconfigured and actually improved over time but it comes with the cost of additional friction and overhead.&lt;/p&gt;

&lt;p&gt;As engineers we are always faced with this &lt;strong&gt;tradeoff between efficiency and flexibility&lt;/strong&gt;. Between a system which is open but incurs overhead and contains redundancies and a tightly integrated closed system which is highly efficient. And as I mentioned before, this is not just applicable to tooling, but to almost every other dimension of a reasonable complex software system. Think Monolith vs Microservices in system architecture, or ESB vs &lt;a href=&quot;https://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes&quot;&gt;Smart Endpoints and Dumb Pipes&lt;/a&gt; in systems integration.&lt;/p&gt;

&lt;p&gt;And software engineering is not the first one to encounter this tradeoff. Clayton Christensen described in his second book &lt;a href=&quot;https://www.amazon.com/Innovators-Solution-Creating-Sustaining-Successful/dp/1422196577/&quot;&gt;The Innovator’s Solution&lt;/a&gt; the &lt;a href=&quot;https://blogs.msdn.microsoft.com/steverowe/2008/02/07/modularization-vs-integration-which-is-best/&quot;&gt;Law of Conservation of Attractive Profits&lt;/a&gt; and related &lt;a href=&quot;https://www.christenseninstitute.org/interdependence-modularity/&quot;&gt;Theory of Interdependence and Modularity&lt;/a&gt;, trying to explain the economic fundamentals behind the success of companies producing tightly integrated closed products vs companies thriving with modular and flexible products. His insight was that when demand is higher than what technology can deliver, closed and tightly integrated systems tend to have a performance edge and win. But the moment technology delivers more than what is demanded, modular and open systems gain the edge by being more innovative. As we discussed above, open and modular systems have an inherent overhead which at that point can be absorbed by the performance surplus generated by the technology. Performance is not longer critical, since the technology at this point produces adequate (= ‘good enough’) performance in both. Which allows other factors like speed of innovation and costs to become decisive.&lt;/p&gt;

&lt;p&gt;If you are curious to explore this topic more, you should check out the &lt;a href=&quot;https://en.wikipedia.org/wiki/Technology_adoption_life_cycle&quot;&gt;Technology Adoption Cycle&lt;/a&gt; as jump off point or read through Christensen’s two part paper on ‘Exploring the limits of the Technology S-curve’: &lt;a href=&quot;https://scinapse.io/papers/1966572897&quot;&gt;Component Technologies&lt;/a&gt; and &lt;a href=&quot;https://scinapse.io/papers/1984187795&quot;&gt;Architectural Technologies&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For a somewhat counter-intuitive argument on being able to combine both efficiency &lt;strong&gt;AND&lt;/strong&gt; flexibility, check out &lt;a href=&quot;https://pdfs.semanticscholar.org/4678/caf882380d931a21010cf606f6113836577a.pdf&quot;&gt;Flexibility vs Efficiency&lt;/a&gt;. This paper analyzes the efforts by a Toyota subsidiary in Fremont, California (known as one of the first successfully mastering Lean in production outside of Japan) on combining botzh flexibility with efficiency. It draws from a wide variety of research in organizational design and social sciences. The story of this plant is probably worth a separate blog post, as it was the worst performing GM facility before it became the best performing facility with the same workers, but with a new management system and philosophy from Toyota (the home of Lean).&lt;/p&gt;

&lt;p&gt;I just do not think that there is a simple right or wrong. There is a time and place for each. If it is about time to value and meeting well defined short term objectives, you might to decide to choose efficiency over flexibility. On the other hand if you are looking longer term and/or want to preserve options for the future in the face of uncertainty, investing into more flexibility might be the better choice. Just make sure to not ‘die in beauty’.&lt;/p&gt;

&lt;p&gt;Maybe next time you are asked to make such tradeoff, answer ‘It Depends’ and think through the consequences of your choice from a larger system perspective. You might still not get it right completely, but at least you had a chance to think about it. And hopefully some of the books and articles I referenced above can help you making a better informed choice - we are &lt;a href=&quot;https://www.youtube.com/watch?v=oLiPRRPaVd4&quot;&gt;Creators of Worlds&lt;/a&gt; after-all. ;)&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Feedback from &lt;a href=&quot;https://twitter.com/mamund&quot;&gt;@mamund&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;This choice between “all-in” on a platform and mix and match your own also has a maturity element. When you first begin, let other make choices for you while you focus on what’s important. As you grow more adept, start to see patterns and “blocks” of functionality in the system (big picture) where you can make changes (add my own monitoring tools, etc.) and, finally, when you are well-versed in the way the system behaves, you can better afford to take on added complexity of choice and flexibility. So in addition there is a maturity-over-time dimension affecting your trade-off.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;From &lt;a href=&quot;https://twitter.com/patkua&quot;&gt;@patkua&lt;/a&gt; in his latest &lt;a href=&quot;http://levelup.thekua.com&quot;&gt;email newletter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;He references two articles which are expressing the need for systems thinking much better than I ever can do: &lt;a href=&quot;https://thesystemsthinker.com/a-lifetime-of-systems-thinking/&quot;&gt;Russel Ackoff: A Lifetime of System Thinking&lt;/a&gt; and &lt;a href=&quot;https://lethain.com//building-evolutionary-architectures/&quot;&gt;Will Larsen’s: Notes on Evolutionary Architecture&lt;/a&gt;&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="systems" /><summary type="html">Or why you should consider taking a course in System Theory.</summary></entry><entry><title type="html">Minecraft Forge install on MacOS</title><link href="https://hlgr360.github.io/blog/blog/minecraft-forge-install/" rel="alternate" type="text/html" title="Minecraft Forge install on MacOS" /><published>2019-11-01T00:00:00+00:00</published><updated>2019-11-01T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/minecraft-forge-install</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/minecraft-forge-install/">&lt;p&gt;Setting up a Minecraft Forge environment for my youngest one to get into programming, I keep being reminded that there are almost no simple step-by-step recipes to install Minecraft Forge on MacOS:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If needed, download and install Java JDK 1.8 from our friends at Oracle at &lt;a href=&quot;https://www.oracle.com/java/technologies/jdk8-downloads.html&quot;&gt;https://www.oracle.com/java/technologies/jdk8-downloads.html&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;If you want to avoid having to register, follow the suggestion in &lt;a href=&quot;https://gist.github.com/wavezhang/ba8425f24a968ec9b2a8619d7c2d86a6#gistcomment-3019424&quot;&gt;this thread&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Download and install Eclipse from &lt;a href=&quot;https://www.eclipse.org/downloads/&quot;&gt;https://www.eclipse.org/downloads/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Download and install GIMP from &lt;a href=&quot;https://www.gimp.org/downloads&quot;&gt;https://www.gimp.org/downloads&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Download Forge 1.11.2 from &lt;a href=&quot;https://files.minecraftforge.net/maven/net/minecraftforge/forge/index_1.11.2.html&quot;&gt;https://files.minecraftforge.net/maven/net/minecraftforge/forge/index_1.11.2.html&lt;/a&gt; (pick the Mdk download option)
    &lt;ul&gt;
      &lt;li&gt;Move the  ‘forge’ directory in ‘Downloads’ to a folder of your choice, i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;Documents&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Create a new directory ‘eclipse’ inside the ‘forge’ directory&lt;/li&gt;
      &lt;li&gt;Open a terminal and navigate to the ‘forge’ directory, i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;cd Documents/forge&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Execute the following command inside of ‘forge’ directory: &lt;code class=&quot;highlighter-rouge&quot;&gt;./gradlew setupDecompWorkspace --refresh-dependencies&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Upon successful build, execute the following command: &lt;code class=&quot;highlighter-rouge&quot;&gt;./gradlew setupDecompWorkspace eclipse&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Open eclipse and select the ‘eclipse’ directory inside your ‘forge’ directory as workspace
    &lt;ul&gt;
      &lt;li&gt;You should now see the MDKExample mod inside the package explorer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above versions are tailored to be used with the &lt;a href=&quot;https://www.udemy.com/course/minecraft-modding-java/&quot;&gt;Minecraft Modding Course&lt;/a&gt; on &lt;a href=&quot;https://udemy.com&quot;&gt;Udemy&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://techwiseacademy.com/minecraft-modding-setting-up-your-environment/&quot;&gt;https://techwiseacademy.com/minecraft-modding-setting-up-your-environment/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.usejournal.com/a-beginners-guide-to-modding-minecraft-9a42536495f6&quot;&gt;https://blog.usejournal.com/a-beginners-guide-to-modding-minecraft-9a42536495f6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="minecraft" /><summary type="html">Simple step-by-step recipe to install Minecraft Forge on MacOS</summary></entry><entry><title type="html">Haufe Blog: Goodbye CTO, Hello Technical Fellow</title><link href="https://hlgr360.github.io/blog/blog/hello-fellow/" rel="alternate" type="text/html" title="Haufe Blog: Goodbye CTO, Hello Technical Fellow" /><published>2019-10-30T00:00:00+00:00</published><updated>2019-10-30T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/hello-fellow</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/hello-fellow/">&lt;p&gt;(this post was originally published on the &lt;a href=&quot;http://work.haufegroup.io&quot;&gt;Haufe Development Blog&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;In the beginning of October 2019 I re-joined the &lt;a href=&quot;https://haufegroup.com&quot;&gt;Haufe.Group&lt;/a&gt; in the role of a Technical Fellow. Needless to say, there were a lot of questions why - as former CTO of Haufe - I would come back and work in the team of my successor &lt;a href=&quot;https://www.linkedin.com/in/raul-firu-3a35121/&quot;&gt;Raul Firu&lt;/a&gt;. And what exactly that role of Technical Fellow would be about.&lt;/p&gt;

&lt;p&gt;Looking back I think both Raul and I never quite gave up the thought that one day we would have a chance to work together and build awesome products (again). So when the chance presented itself, it was the question how, not if we would want to work together again. The starting point of our discussion about a possible role was the very inspirational &lt;a href=&quot;https://www.thekua.com/atwork/2019/03/goodbye-cto-hello-chief-scientist/&quot;&gt;blog post from Patrick Kua&lt;/a&gt; titled ‘Goodbye CTO, Hello Chief Scientist’ (from which I shamelessly stole the title of my blog post).&lt;/p&gt;

&lt;p&gt;There are aspects of the CTO role which I love and would not want to miss: the opportunity to mentor and grow individuals and teams, the impact I can have on products, customers and markets, and working within organizations and their leaderships to align the culture, structure and technology to allow us to deliver. What I liked less were the inherent distance to execution  and impact through the layers of hierarchy in large organizations and a calendar filled with meetings with little practical control over if I could attend or not.&lt;/p&gt;

&lt;p&gt;From a Haufe perspective Raul was very clear that he would like to see me in an technologist and evangelizer role, serving both the tech community internally and representing Haufe technology to the outside.  While a role of an evangelizer and technology scout comes very natural to me, I felt that my opinions (or some would say preaching ;) needed to be grounded not just in ‘desk research’ but in some form of operational responsibilities too. To be able to convince and challenge I had to not just ‘talk the talk’, but ´walk the walk´: to show that something is true by actions rather than words. On this cue - have I mentioned that I love building products? So we created a hybrid role which combines time-boxed operational responsibility in business undergoing transformational change with the role of mentoring, evangelizing and technology scouting.&lt;/p&gt;

&lt;p&gt;But with the operational responsibility the term ‘Chief Scientist’ did not feel like a good fit anymore. So we came up with the title of a Technical Fellow.&lt;/p&gt;

&lt;p&gt;What exactly does a Technical Fellow do? We settled on the following 3 areas (I quote from Raul’s email):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An operational but time-boxed role in technology transformation (following the principle of alignment of technology/structure/culture) for products or businesses going through a significant change.&lt;/li&gt;
  &lt;li&gt;Leveraging Holger’s natural evangelist skills: blog posts, presentations, trainings / up-skilling, presenting Haufe’s engineering culture externally.&lt;/li&gt;
  &lt;li&gt;Supporting the Group CTO and the business leadership in making significant or strategic decisions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So in a nutshell, a Technical Fellow has small circle of control, but large circle of influence. (Which itself is a concept adopted from the book &lt;a href=&quot;https://blog.hubspot.com/sales/habits-of-highly-effective-people-summary&quot;&gt;7 Habits of Highly Effective People&lt;/a&gt;, which - if you haven’t read it - I highly recommened flipping through in the linked summary.) The role doesn’t just bring significant value to Haufe, but also plays to my core strength as passionate (product) builder and technologist.&lt;/p&gt;

&lt;p&gt;I am very excited about this new role and its challenges, both professionally and personally. It is certain to force me to venture outside my comfort zone as former C-level executive. While &lt;a href=&quot;https://en.wikipedia.org/wiki/Here_be_dragons&quot;&gt;there might be dragons&lt;/a&gt; ;) on that journey, I think growth is only found outside of the level of comfort. I do not think I can express it more beautifully than how Patrick said it in his blog post: “Here’s to embracing constant change, evolution and experimentation!”&lt;/p&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="blog" /><category term="culture" /><summary type="html">Hic sunt dracones - There Might Be Dragons.</summary></entry><entry><title type="html">AWS Lambda CloudWatch Logging</title><link href="https://hlgr360.github.io/blog/blog/aws-logging/" rel="alternate" type="text/html" title="AWS Lambda CloudWatch Logging" /><published>2019-10-29T00:00:00+00:00</published><updated>2019-10-29T00:00:00+00:00</updated><id>https://hlgr360.github.io/blog/blog/aws-logging</id><content type="html" xml:base="https://hlgr360.github.io/blog/blog/aws-logging/">&lt;p&gt;AWS does an awesome job in documenting its services and APIs, no questions about it. But during my quest of building Microservices Architecture on AWS Lambda I keep encountering those ‘places in between’, when using AWS Lambda together with other AWS Services just drops me into rabbit hole of trying to find the missing nuggets of knowledge or code samples to make things actually work together.&lt;/p&gt;

&lt;p&gt;So today’s blog post is about debugging. Just plain old debugging. Nothing fancy, just plain old &lt;code class=&quot;highlighter-rouge&quot;&gt;console.log()&lt;/code&gt; will do the trick. So you add your logs, deploy your lambda and head over to the CloudWatch console to nail that nasty lambda timeout bug which keeps you up at night.&lt;/p&gt;

&lt;p&gt;Lets say you are not just playing but have a constant stream of function invocations .. so I bet you quickly hit upon to type ‘Task timed out’ in the search bar above the log stream, and bang - you see all the timed out lambdas. So far so good. Except it is only the last line of that lambda invocation which matches your expression.&lt;/p&gt;

&lt;p&gt;But not to despair - you might have noticed that each Lambda invocations is framed in a START, END and REPORT log, which includes a &lt;code class=&quot;highlighter-rouge&quot;&gt;RequestId&lt;/code&gt; unique to that invocation. And each log generated from within the lambda code also has the &lt;code class=&quot;highlighter-rouge&quot;&gt;RequestId&lt;/code&gt;prepended. So surely I should be able to type that &lt;code class=&quot;highlighter-rouge&quot;&gt;RequestId&lt;/code&gt; value into the search and see all logs generated by that function invocation.  Makes total sense, or? Thought so?&lt;/p&gt;

&lt;p&gt;You are so wrong (like me) :). Yep, searching for the RequestId in the CloudWatch console does &lt;strong&gt;nada, nothing, nichts&lt;/strong&gt;. No log, no game.&lt;/p&gt;

&lt;p&gt;Next step deeper into the rabbit hole, fire up your browser and start searching … Grrrr! Why am I the only one who wants to get the logs of a lambda invocations grouped together. What am I missing? Yes, I could install yet another library but no thank you - I just want my transaction log.&lt;/p&gt;

&lt;p&gt;So I open a query on our development chat and a dear colleague of mine  comes to the rescue: Type &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;RequestId: &amp;lt;request-id-here&amp;gt;&quot;&lt;/code&gt; in the search bar (including quotes). I was back in the game. And I could finally filter for the outer frame of the lambda invocation (START, END, and REPORT). But wait .. dude, where are &lt;strong&gt;MY&lt;/strong&gt; logs? Why the hell would you (yes, you AWS - I am talking to you) prepend &lt;strong&gt;MY&lt;/strong&gt; logs with the request id but then not show it together with the outer ones.&lt;/p&gt;

&lt;p&gt;You got to be kidding me .. another frantic search across message boards and the world-wide-web. Finally a first hint two references across and hidden deep inside a &lt;a href=&quot;https://github.com/aws/aws-sdk-js/issues/781#issuecomment-154499642&quot;&gt;thread on a message board&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Wait what .. could it be a simple pattern matching .. not RequestId as in ‘the Request ID of a lambda invocation’ but as in literally &lt;code class=&quot;highlighter-rouge&quot;&gt;RequestId: &lt;/code&gt;?&lt;/p&gt;

&lt;p&gt;And you might have guessed it, prepending my log with  &lt;code class=&quot;highlighter-rouge&quot;&gt;RequestId: &lt;/code&gt; now makes it show up as part of the invocation.&lt;/p&gt;

&lt;p&gt;So here is the magic syntax to log within your lambda function and make it searchable as part of the request in the CloudWatch console.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export async function get(event, context) {

    console.log(
        &quot;RequestId: &quot; +
            context.awsRequestId +
            &quot; UserId: &quot; +
            userId +
            &quot; Path: &quot; +
            event.path +
            &quot; Query: &quot; +
            JSON.stringify(event.queryStringParameters)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;May the (logging) power be strong in you.&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/de_de/lambda/latest/dg/nodejs-prog-model-context.html]&quot;&gt;https://docs.aws.amazon.com/de_de/lambda/latest/dg/nodejs-prog-model-context.html]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/getndazn/dazn-lambda-powertools]&quot;&gt;https://github.com/getndazn/dazn-lambda-powertools]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/hackernoon/centralised-logging-for-aws-lambda-b765b7ca9152]&quot;&gt;https://medium.com/hackernoon/centralised-logging-for-aws-lambda-b765b7ca9152]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;Update after a comment from my former colleague &lt;a href=&quot;https://www.linkedin.com/in/diogo-henriques-4b77083a/&quot;&gt;Diogo&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;He pointed me to the CloudWatch Insight console as an alternative method. After a couple of minutes of playing around I got the hang of it and it does indeed allow for filtering of the metadata of a log event such that all logs belonging to a single transaction can be shown.&lt;/p&gt;

&lt;p&gt;At a basic level it is quite simple. You select the Log Group of your lambda endpoint, and then click together (or type) a filter expression like &lt;code class=&quot;highlighter-rouge&quot;&gt;filter @requestId=&quot;da1515da-09c8-4112-b50b-27a4bb04f058&quot;&lt;/code&gt;. Pay attention to the time period the query should cover.&lt;/p&gt;

&lt;h4 id=&quot;references-1&quot;&gt;References&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_AnalyzeLogData-discoverable-fields.html&quot;&gt;https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_AnalyzeLogData-discoverable-fields.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Holger Reinhardt</name><email>holger@launchd.de</email></author><category term="development" /><category term="aws" /><summary type="html">How to group AWS Lambda Logs by RequestId</summary></entry></feed>